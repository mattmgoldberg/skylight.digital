---
layout: toolkit
title: Appendix
permalink: /work/toolkits/agile-procurement-playbook/appendix
sidenav: agile_procurement_playbook
---


# Appendix A: Short introduction to agile software development

Agile is a time-bound, iterative approach to software delivery that
builds software incrementally from the start of the project, instead of
trying to deliver all at once. There is typically a cadence called
sprints in which the team commits to delivering artifacts at the end of
each for review. These artifacts can be working software, user personas,
wireframes, etc.

By taking this approach of delivering working software at the end of
each sprint, progress can be closely monitored and course corrected
throughout the lifetime of the product. This iterative approach to
product and software development focuses on de-risking the ultimate
delivery of product. This approach will require more involvement from
key stakeholders to ensure that the product is on track towards
delivery.

Appendix B: List of templates
-----------------------------

## Quality Metric Plan Template

QUALITY MANAGEMENT PLAN (QMP)

**Introduction**

This Quality Management Plan (QMP), which contains a
Quality Assurance Surveillance Plan (QASP) and Quality Control Plan
(QCP) is pursuant to the requirements listed in the performance-based
\[Performance Work Statement (PWS) or Statement of Objectives (SOO)\]
for \[program that the procurement is being ran against\], agile
development services. This performance-based plan sets forth the
procedures and guidelines the \[agency name\] will use in evaluating the
technical performance of the contractor’s services as required beneath
the Task Order.

After acceptance of the quality management plan the Vendor shall receive
the Government Contracting Officer’s acceptance in writing of any
proposed change to his Quality Control system.

**Purpose**

This QMP has been developed to evaluate Vendor actions while
implementing this \[PWS or SOO\]. It is designed to provide an effective
surveillance method of monitoring Vendor performance for each listed
deliverable. By employing a fully developed QMP, the Government and the
Vendor achieve an understanding of performance expectations and how
performance will be measured against those expectations.

The QMP is designed to define roles and responsibilities, identify the
performance objectives, define the methodologies used to monitor and
evaluate the contractor’s performance, describe quality assurance
reporting, and describe analysis of quality assurance monitoring
results.

The goals for the quality management plan are to provide the best means
to ensure contract standards and deliverables meet their stated
requirements and project management processes are appropriately followed
to maintain a high metric of performance and quality.

**Performance Management Strategy**

The contractor’s internal quality control system will set forth the
staffing and procedures for self inspecting the quality, timeliness,
responsiveness, customer satisfaction, and other performance
requirements in the PWS. The contractor will utilize its internal
quality control system to assess and report their performance to the
designated Government representative.

The Government representative will monitor performance and review
performance reports furnished by the contractor to determine how the
contractor is performing against communicated performance objectives.
The Government will make decisions based on performance measurement
metric data and notify the contractor of those decisions. The contractor
will be responsible for making required changes in processes and
practices to ensure performance is managed effectively.

**Roles and Responsibilities**

The Contracting Officer (CO) is responsible for monitoring contract
compliance, contract administration and cost control; and resolving any
differences between the observations documented by the Contracting
Officer’s Representative (COR) and the contractor’s performance.

The CO will designate one full-time COR as the Government authority for
performance management. The number of additional representatives serving
as Technical Inspectors, such as respective Product Owner(s), depends
upon the complexity of the services measured as well as the contractor’s
performance.

The COR is responsible for monitoring, assessing, and communicating the
technical performance of the contractor and assisting the contractor.
The COR will have the responsibility for documenting the inspection and
evaluation of the contractor’s work performance. Government surveillance
may occur under the Inspection of Services clause for any services
relating to the contract.

**Performance Management Approach**

The performance-based \[PWS or SOO\] structures the acquisition around
“what” services are required as opposed to “how” the contractor should
perform the work. This QMP will define the performance management
approach taken by the \[agency name\] to monitor, manage, and take
appropriate action on the contractor’s performance against expected
outcomes or performance objectives communicated in the \[PWS or SOO\].
Performance management rests upon developing a capability to review and
analyze information generated through performance metrics. The ability
to make decisions based on the analysis of performance data is the
cornerstone of performance management. The data generated in a
performance management approach provides information that indicates
whether or not expected outcomes for required services are being
achieved adequately by the contractor.

Performance management also represents a significant shift from the more
traditional Quality Assurance (QA) concepts in several ways. Performance
management focuses on assessing whether or not outcomes are being
achieved and migrates away from scrutiny on compliance with the
processes and practices used to achieve the outcome. The only exceptions
to process reviews are those required by law (Federal, State, and local)
and compelling business situations such as safety and health. An outcome
focus provides the contractor flexibility to continuously improves and
innovate over the course of the contract as long as the critical
outcomes expected are being achieved at the desired levels of
performance.

**Performance Management Strategy**

The contractor’s internal quality control system will set forth the
staffing and procedures for self inspecting the quality, timeliness,
responsiveness, customer satisfaction, and other performance
requirements in the PWS. The contractor will utilize its internal
quality control system to assess and report their performance to the
designated Government representative.

The Government representative will monitor performance and review
performance reports furnished by the contractor to determine how the
contractor is performing against communicated performance objectives.
The Government will make decisions based on performance measurement
metric data and notify the contractor of those decisions. The contractor
will be responsible for making required changes in processes and
practices to ensure performance is managed effectively.

**Quality Assurance Surveillance Plan**

The Vendor shall develop and maintain effective quality assurance
metrics to ensure services are performed in accordance with this Task
Order and include the Quality Assurance metrics either within the
Quality Metrics Table or as an attachment to this QMP with their quote.
The focus of quality assurance is on the processes used to deliver.
Quality assurance ensures that processes are used effectively to produce
quality project deliverables. It involves following and meeting
standards, continuously improving project work, and correcting project
defects.

**Quality Control Plan**

The Vendor shall develop and maintain effective quality control metrics
to ensure services are performed in accordance with this Task Order and
include the Quality Control metrics either within the Quality Metrics
Table or as an attachment to this QMP with their quote. The Vendor shall
develop and implement procedures to identify, prevent, and ensure
non-recurrence of defective services. The Vendor’s quality control plan
is the means by which the Vendor assures that their work complies with
the requirement of the contract.

The focus of quality control is on the deliverables of the project.
Quality control monitors project deliverables to verify that the
deliverables are of acceptable quality and the customer is satisfied.

**Evaluation Methods**

The methods of evaluating Vendor compliance may vary depending on the
PWS. The COR is responsible for selection of the method(s) to be used
and the specific detailing of the method(s). The following describes
alternative methods of observation:

**100 Percent Evaluation**

This is the appropriate method of evaluating infrequent tasks or tasks
with stringent performance requirements, e.g., where safety or health is
a concern. With this method, performance is inspected/evaluated at each
occurrence. One hundred percent inspection is too expensive to be used
in most cases.

**Random Review**

This is an appropriate method of surveillance for recurring tasks.
Random sampling works best when the number of instances of the services
being performed is very large and a statistically valid sample can be
obtained.

**Customer or Other Government Feedback**

Customer feedback can come from interaction with the general public or
through interaction with Government employees and other Government
Offices/Agencies. Although usually not a primary method, this is a
valuable supplement to more systematic methods. For example, in a case
where random sampling indicates unsatisfactory service, customer
complaints can be used as substantiating evidence. In certain situations
where customers can be relied upon to complain consistently when the
quality of performance is poor, e.g., dining facilities, building
services; customer surveys and customer complaints may be a primary
surveillance method.

**Performance Criteria**

**Acceptable Performance**

Acceptable performance meets the specified standard and does not exceed
the allowable deviation. The Government may conduct trend analysis of
surveillance results to increase or decrease the level of surveillance
for specific requirements.

**Unacceptable Performance**

Unacceptable performance does not meet the specified standard and
exceeds the allowable deviation/acceptable quality level. The contractor
may receive deductions or even termination based on failure to perform/
deliver at the acceptable quality level. The following criteria apply
for determining appropriate action:

> 1\. *Notifications.* Consistent with FAR Part 49, the CO shall notify the
> service provider of failure to meet standards through quality
> performance monitoring forms, cure notices, or show cause notices and
> shall inform the service provider project manager or designated
> alternate of such notices.
>
> 2\. *Deductions.* The Government has the right to withhold a percentage
> or value of payment of the iteration cost for performing particular
> services based on failure to meet performance standards/metrics. The
> percentage or value of such withholdings is identified in the Quality
> Measures/Metrics table.
>
> 3\. *Termination.* If the CO determines that the contractor has failed to
> perform to the extent that a termination for default is justified, the
> CO shall issue a notice of termination, consistent with FAR Part 49.
>
> 4\. *Government Remedies.* “The Government Contracting Officer shall
> follow FAR 52.212-4, “Contract Terms and Conditions-Commercial Items”
> for Vendor’s failure to perform satisfactory services or failure to
> correct non-conforming services.”

**Performance Criteria Quality Measures / Metrics**

**QUALITY MEASURES / METRICS**

| Process/Deliverable | Delivery/Performance Standards | Allowable Deviation/Acceptable Quality Level | Method of Assessment | Date/Schedule | Iteration Payment Impact |
|---------------------------------------------------------------------------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|
|  Instructions: Indicate Tasks from SOO.   Please add any additional tasks, as needed. | Instructions: Indicate expectations or standards. | Instructions: Indicate “none” if there is no allowable deviation or e.g., “100% of calendar arrangements are correctly processed within 6 days”, or “2 day slippage allowance from due date”, etc. | Instructions: Indicate how often this task will be reviewed, e.g., “Random review”, “100% review”, or “Quarterly review”, etc. | Instructions: Indicate when the task is due with a specific date or e.g., “On-going”, “daily”, “quarterly”, etc. | Instructions: Indicate what the associated impact to payment of iteration is or if not applicable |
|TO BE COMPLETED/PROPOSED BY QUOTER|  |  |  |  |  |
|  |  |  |  |  |  |
|  |  |  |  |  |  |
{: .table style="font-size:15px"}

## Additional Quality Metrics Table Template from [*18F*](https://github.com/18F/technology-budgeting/blob/master/handbook.md#appendix-b-sample-quality-assessment-surveillance-plan-qasp)

Here is an example of a Quality Metrics Table that includes a QASP.
[*Source*](https://github.com/18F/technology-budgeting/blob/master/handbook.md#appendix-b-sample-quality-assessment-surveillance-plan-qasp)


|  Deliverable | Performance Standard(s) | Acceptable Quality Level | Method of Assessment |
| --- | --- | --- | --- |
|  Tested Code | Code delivered under the order must have substantial test code coverage and a clean code baseVersion-controlled, public repository of code comprising the product, which will remain in the government domain | Minimum of 90% test coverage of all code | Combination of manual review and automated testing |
|  Properly Styled Code | [GSA 18F Front-End Guide](https://frontend.18f.gov/) | 0 linting errors and 0 warnings | Combination of manual review and automated testing |
|  Accessibility | Web Content Accessibility Guidelines 2.1 AA standards | 0 errors reported using an automated scanner, and 0 errors reported in manual testing | [Pa11y](https://github.com/pa11y/pa11y) |
|  Deployed | Code must successfully build and deploy into staging environment | Successful build with a single command | Combination of manual review and automated testing |
|  Documented | All dependencies are listed and the licenses are documented. Major functionality in the software/source code is documented. Individual methods are documented inline using comments that permit the use of documentation-generation tools such as [JSDoc](http://usejsdoc.org/). A system diagram is provided | Combination of manual review and automated testing, if available | Manual review |
|  Security | [OWASP Application Security Verification Standard 4.0, Level 2](https://www.owasp.org/images/d/d4/OWASP_Application_Security_Verification_Standard_4.0-en.pdf) | Code submitted must be free of medium- and high-level static and dynamic security vulnerabilities | Clean tests from a static testing SaaS (such as [npm audit](https://docs.npmjs.com/cli/audit)) and from [OWASP ZAP](https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project), along with documentation explaining any false positives |
|  User research | Usability testing and other user research methods must be conducted at regular intervals throughout the development process (not just at the beginning or end) | Artifacts from usability testing and/or other research methods with end users are available at the end of every applicable sprint, in accordance with the vendor’s research plan | Manual review |
{: .table}

Appendix C: Examples of TEP rating systems
------------------------------------------

The TEP and contracting experts have wide laditude in determining how
they are going to be evaluating proposals. Picking a system in which
rating will be made is important in how the overall selection is going
to be made.

## Confidence Factors

A confidence rating system reflected the government’s confidence on
whether a vendor will be able to successfully build the product based on
the proposal submitted.

**High Confidence:** The Government has ***high confidence*** that the
Offeror understands the requirement, proposes a sound approach, and will
be successful in performing the contract with ***little or no***
Government intervention.

**Some Confidence:** The Government has ***some confidence*** that the
Offeror understands the requirement, proposes a sound approach, and will
be successful in performing the contract with ***some*** Government
intervention.

**Low Confidence:** The Government has ***low confidence*** that the
Offeror understands the requirement, proposes a sound approach, or will
be successful in performing the contract ***even with*** Government
intervention.

## Adjectival Ratings

An adjectival rating system for scoring will be utilized and the
technical panel will determine final scoring, based on a consensus. The
following is the adjectival rating system that will be used to evaluate
proposals.

**Exceptional:** Greatly exceeds all minimum requirements of the
criteria; has a high probability of success; contains no weaknesses or
deficiencies.

**Good:** Exceeds all the minimum requirements of the criteria; has an
above average probability of success; contains no significant weaknesses
and only minor, correctable weaknesses exist.

**Acceptable:** Meets all the minimum requirements of the criteria; has
an average probability of success; any weaknesses can readily be
corrected; no deficiencies exist.

**Unacceptable:** Fails to meet the minimum requirements of the
criteria; contains multiple significant weaknesses or one or more.

Appendix D: Example Design Challenges
-------------------------------------

Typically a design challenge should resemble the type of work that the
government hopes to procure. This can take a variety of forms, from
working software proof-of-concepts to visual artifacts that include
journey maps and user personas, examples of what product development
would look like through various tools such as Jira and Confluence. It is
important that the [*technical evaluation
panel*](#technical-evaluation-panel-tep) has a cross representation of
digital experts to evaluate the vendor technical solutions for best
practices.

Here is an example of a recent design challenge put on by CMS.

## [*The Medicare Payment System Modernization*](https://usds.gov/projects/medicare-payment-program) [*Design Challenge*](https://fcw.com/blogs/lectern/2019/07/kelman-non-traditional-contractors.aspx)

Imagine that you have come upon the large monolithic legacy system
responsible for executing and maintaining the workflow that processes
Medicare claims in order to make payments to service providers. The
maintenance of the system is proving to be unsustainable as time
continues. We want you to modernize this system.

In addition to the existing payment processing system, there are other
parts of the agency that are involved in experimental payment workflows
that traditionally operated outside of the legacy payment system. We
want those experimental workflows incorporated into this modernization
effort. This will require the integration of two very different work
streams, development processes, and development lifecycles. The Medicare
payment processing workflow is ever-evolving to respond to legislative
changes and new industry paradigms. The existing system and any
subsequent changes to modernize it, must take into consideration the
flexibility that is required to quickly react to these types of changes
so that business is not interrupted.

This work is fundamental to the agency’s mission and will require teams
that can take pragmatic steps toward modernizing the legacy systems as
well as supporting new payment workflows in the future. Due to the
complexity of the work, teams must be comfortable with requirements that
are vague, undefined, or conflicting. Thus, we will not provide a
detailed list of requirements. Instead, we will provide an outline of
how we will evaluate your solution, and a list of the outcomes we will
measure and use in the evaluation.

CMS has given you the following goals while approaching the
modernization of this system:

-   Sustainability: the system, resources, and processes must maintain
    their current levels of service during modernization efforts
-   Agility: the system needs to evolve, sustainably, at the same speed
    as the business
-   Integration: systems involved in making payments, and other CMS
    business functions, need the option to use modern technology to
    interact with the current state of the legacy system.
-   Usability: users’ interaction with the legacy system need to easily
    identify and extract the exact data they need, when they need it.

With the goals provided and as part of this design challenge, CMS wishes
you to help develop a longer-term vision and product strategy for
this modernization effort.

Because the existing system is so large and has many groups that are
involved with maintaining it, there are competing business needs that
will require prioritizing development work. Knowing what to immediately
modernize can change based on shifting business requirements. These
potential changes shouldn’t impact the longer-term vision of the
modernization effort.

The business owners of the current system have identified modules that
need “modernization”. In addition to these modules that currently run on
the mainframe to support existing payment methodologies, Other business
owners are developing new payment methodologies and would like the new
system to be flexible enough to accommodate both existing and new
methods simultaneously. CMS executives want to understand both why and
how the work that you’ve chosen to do accomplishes the project’s goals
that CMS has provided and the vision that you have created.

**Business Owner 1:** In order to support existing fee-for-service
claims payment processing, maintenance is provided yearly on a specific
piece of business logic called “FQHC-Pricer”. The pricer that the
business owner wants you to address is currently written in COBOL and
has been maintained by CMS for 15 years. The pricer is a self-contained
module that does not require any database access or outside
dependencies. These yearly code changes typically take at least 8 months
to implement due to a waterfall process of requirements gathering,
planning, developing, testing, and deploying. The business owner wishes
to make changes to the pricer that can be pushed out to production in a
much more rapid cadence.

These files don’t have the most extensive testing associated with them.
CMS policy should have the expected outputs based on inputs but because
they are removed from the development lifecycle, their inputs/outputs
may or may not match what was actually development. You should plan for
these inconsistencies by providing how you will determine parity and
address each discrepancy, if any.

**Business Owner 2:** In order to integrate new payment methodologies
into the existing business workflow, creating services that can be
reused is desired. One such example of a service is identifying
participants. Each new payment methodology, called models, requires
identifying participating providers or institutions. Once participants
have been identified and other required information provided, that
“file” needs to loaded into the legacy system. There are many models,
each with their own development teams, that submit participant
information to the legacy system in various different formats. The
legacy system requires a standardized format. Explain how you will
address the issue of lack of standard submissions and a service-design
workflow.

**Deliverables**

You are to prioritize the above business owners’ needs with your
deliverables and provide justifications for decisions made. These
decisions should be in sync with your proposed long-term vision for this
system. CMS is looking to you to provide software artifacts that deliver
on the business needs and support those artifacts with research, design,
and product roadmaps.

Appendix E: Sample Analysis of Procurement Options
--------------------------------------------------

In deciding which procurement strategy would best fit the needs of a
product, developing an analysis of alternatives for the different
options that are available helps provide data to make decisions.

Here is an example of an analysis of alternatives that the Centers for
Medicare and Medicaid Services (CMS) did when determining which
contracting vehicle would best support the product.

## Medicare Payment Modernization Contracting Strategy

As modernization efforts transitions from proof of concepts on the
Fiscal Intermediary Standard System (FISS) to a production roadmap,
serious thought must be put into the contracting strategy to support
this effort for the next 5-10 years. ***Setting up the correct
contracting strategy has the largest impact on the probability of
success on this effort***. The FISS system is the initial target for
proof of concepts to be transitioned into production, this effort
shouldn’t be limited to just that system. This is a unique opportunity
to synthesize diverse Medicare payment systems. Including the following:

* Common Working File (CWF)
* Multi-Carrier System (MCS)
* VIPS Medicare Shared System (VMS)
* CMMI models

To achieve the goal of a successful payment modernization effort,
contracting strategy must enable the following factors:

* Ability to award new tasks quickly
* Quality of technical talent available via contract vehicle
* Contractor Digital Service experience and approach (this is
different than “agile development”)
* Familiarity with CMS systems, specifically complex business logic
associated with Medicare FFS payment processing
* Ability to define development and infrastructure requirements at the
BPA level so details are not missed in task orders

There exists a variety of contracting options, each with pros and cons.
It is the effort of this document to determine which contracting option
best suits needs for this modernization effort. Ultimately, the decision
on choosing the right contracting strategy needs to answer the simple
question of: Will this vehicle/strategy position the Medicare Payment
Modernization effort to have the greatest probability of success?

***SPARC***

OIT at CMS has an existing IDIQ, SPARC, that is the agency’s answer to
agile, waterfall, and hybrid development methodologies. This vehicle has
a \$25B ceiling that houses over 140 different vendors. Its goal is to
be the one-stop shop for agency development. There are certainly
advantages to leveraging work already completed as well as drawbacks to
leveraging a generic development contacting vehicle.


|  Pros | Cons |
| :--- | :--- |
|  The IDIQ is already existing and vendors have been pre-vetted. | The vendor pool is not specialized to any project. |
|  The vendor pool is diverse based on company size. | The vendor pool is so large the agile contracting is impossible. |
|  The ceiling on the IDIQ is extremely high – low risk of breaking through it. | The probability of protest per contract is substantially higher due to more vendor bids and issues with small business sizes. |
|  Orders under $10M are not protestable. | Agile methodologies, user-center design, user design, and DevOps practices are not baked into the IDIQ and thus need to be included with each proposal. This bloats the proposal with boilerplate language while increasing the surface area of protest. |
|  All contract types permissible giving CMS added flexibility. | Most vendors are not familiar with CMS payment processing and could struggle to meet the quick on boarding and rapidly changing needs of this project |
|  Helping CMS meet small business goals. | Ability to award new tasks quickly. |
{: .table}

***SPARC with on-ramp***

This option has the ability to continue leveraging SPARC while allowing
for new vendors to be added to the IDIQ. This list includes all of the
Pros and Cons listed previous with SPARC with the following
consideration.

|  Pros | Cons |
| :--- | :--- |
|  Ability to add new entrants to the cadre of pre-qualified vendors that could compete for agile development work | High protest probability - would require a competitive process which could be protested – there are two points of protest because we already have a large vetted pool of contractors plus the source selection decision |
|  - | Additional resources need on OAGM and program side to manage source selection process |
{: .table}

***GWAC – Alliant 2, CIO SP3***

|  Pros | Cons |
| :--- | :--- |
|  Existing pre-vetted cadre of qualified vendors | BIC designation which will help CMS meet OMB targets |
|  Orders under $10M not protestable | Agency could receive criticism for not using SPARC which was intended, in part, for agile development; however, climate is pushing agencies toward Category Management and SUM/BIC use |
|  All contract types permissible | Not all vendors will have subject matter expertise with CMS systems or payment processing |
|  Alliant 2 explicitly includes agile development services |  |
{: .table}

***Agency Wide BPA***

|  Pros | Cons |
| :--- | :--- |
|  Targeted competition possible; however, must provide RFQ to any company requesting it | Vendors are not tailored to the project’s specific goals. |
|  Ability to reach new contractors who have entered the market for initial competition | Initial award and any calls are protestable |
|  BPA holders will be specifically selected based upon demonstrated ability to develop and deploy digital services using agile methodologies, user centered design and DevOps. | New umbrella contract vehicle is resource intensive versus placing individual orders against existing contract vehicles |
|  Could receive OMB designation as a SUM vehicle but requires mandatory use policy and other reporting requirements | If significant overlap to existing SUM/BIC vehicle, modified business case to OMB required |
|  - | If approved by OMB, and BPA put in place, CMS mandatory use policy and rigorous reporting requirements needed |
|  - | Inability to add new contractors to mix after award of BPA |
|  - | Risk of ending up with a significant number of vendors in pool |
|  - | Agency could receive criticism for not using SPARC which was intended, in part, for agile development |
{: .table}

***GSA Schedule Task Order Competitions***

The GSA Schedule is available for individual task orders as they are
necessary.

|  Pros | Cons |
| :--- | :--- |
|  Existing pre-vetted cadre of qualified vendors | Not a SUM or BIC vehicle. |
|  New contractors are constantly being added to the industrial base. | Hundreds of vendors; however, FPDS data shows that [x] proposals are received on average |
|  Targeted competition possible (to reasonably ensure receipt of at least 3 quotations); must provide RFQ to any company requesting it. | Limited to FFP or L-H; however, these contract types are consistent with commercial practices for buying agile development |
{: .table}


***Project Specific BPA off of GSA Schedule***

|  Pros | Cons |
| :--- | :--- |
|  The vendors are tailored to the project’s needs | Initial award and any calls are protestable |
|  Contracts can be issued as new problems or requirements are encountered. | Multiple program specific BPAs are resource intensive for the agency to award and manage |
|  Smaller pool of specialized vendors. | If the vendors are smaller companies, there is risk of being unable to meet the needs of the total work necessary for the project. |
|  The pool of vendors all become domain experts as the project matures. | If significant overlap to existing SUM/BIC vehicle, modified business case to OMB required |
|  Agile methodologies, user-center design, user design, and DevOps practices can be baked into the BPA. This avoids proposals with boilerplate language while focusing on the objectives. | If approved by OMB, and BPA put in place, CMS mandatory use policy and rigorous reporting requirements needed |
|  The base period on awarded contracts is shorter.<br/> <br/>CMS is put into the position of less risk by requiring results from vendors faster.<br/> <br/>CMS does not have the pressure to award existing vendors on a contract re-compete due to transition time shorten via domain knowledge. This drive competition. | - |
|  Avoids single points of failure. Re-competes are actually encouraged. | - |
{: .table}

While there are a variety of potential contracting options available, to
date, the most successful approach to complex system development at CMS
using an innovative, Digital Service approach, was done on the Quality
Payment Program.

Some high-level stats on the QPP BPA to date:

* There have been 16 task orders awarded under ADELE.
* All vendors are small businesses.
* Every ADELE BPA holder has won an award at this point.
* All ADELE task orders have been competitively awarded.
* Zero Protests.
* The average procurement action lead time is 67 days.
* The average Period of Performance for an ADELE task order is 2.2
years.
* Responses were typically limited to 20-25 pages with 2-week
turnarounds.
* Low dollar value allows for COR II rather than COR III.

***A Tale of Two Contract Vehicles: A Retrospective***

As previously listed, the goals for our contracting strategy are:

* Ability to award new tasks quickly
* Quality of technical talent available via contract vehicle
* Contractor Digital Service experience and approach (this is
different than “agile development”)
* Familiarity with CMS systems, specifically complex business logic
associated with Medicare FFS payment processing
* Ability to define development and infrastructure requirements at the
BPA level so details are not missed in task orders

CMS has experience over the past year issuing contracts through both
SPARC and ADELE and there are some great data points that can be
gathered to compare the two vehicles against the goals that we are
aiming for.

***Ability to award new tasks quickly***

Working in an agile fashion means not having all of the business
requirements up front. Most of the time this process is impossible and a
vast majority of the time the initial business requirement gathering for
a complex system is incorrect. As new requirements come to light
throughout the modernization process, the ability to issue contracts
rapidly is necessary.


|  **Vehicle** | **Ability to award new tasks quickly** |
| :--- | :--- |
|  SPARC | Competitive task orders averaged 139 days (19.9 weeks) |
|  ADELE BPA | Competitive task orders averaged 67 days. (9.5 weeks) |
{: .table}


***Quality of technical talent available via contract vehicle***

Competition is vital in making sure the government is getting the best
possible vendor for the job. More vendors does not always mean better
competition. Contracts see the best competition when vendors specialize
in the work that issued. Overall competition increases as vendors learn
through previous proposals. Finding the sweet spot of the vendor pool
size that allows for competition and allows vendors to continuously
challenge each other to rise the skill level is important.

|  **Vehicle** | **Quality of technical talent available via contract vehicle** |
| :--- | :--- |
|  SPARC | The density of high skilled vendors is variable. Roughly 5% of the total vendors have won a competitive proposal under SPARC. |
|  ADELE BPA | 100% of the vendors have won a competitive proposal under ADELE. Each one of these competitive proposals included a design challenge that required working software and designs to be submitted. |
{: .table}

***Contractor Digital Service experience and approach (this is different
than “agile development”)***

User-centered design, user research, devops, and product management are
required to deliver modern digital services. These skill sets along with
an agile methodology are necessary in delivering working software in
small increments allowing for quickly changing development and design as
new requirements are discovered.


|  **Vehicle** | **Contractor Digital Service Experience** |
| :--- | :--- |
|  SPARC | Partners offer agile, waterfall, and hybrid development methodology. Having digital service skill sets were not prerequisites for joining SPARC. |
|  ADELE BPA | 100% of the vendors on ADELE went through market research making sure that modern digital services and agile development practices were core to their business. |
{: .table}

***Familiarity with CMS systems, specifically complex business logic
associated with Medicare FFS payment processing***

Having a background with CMS programs allows vendors to hit the ground
running when contracts are awarded. The amount of time that is required
to either onboard or transition work is diminished when vendors already
know systems that they will be working on. Having these familiarities
allows for the period of performance to decrease and thus protecting CMS
from getting locked into a vendor that underperforms. In addition to
familiarity, having a smaller vendor pool means that contractors and
their employees already have accounts, access and the ability to quickly
begin work after contract award.

In some cases it takes over two months for *new* contractors to get
access to CMS systems, this would make any attempt at iterative
development dead on arrival.

|  **Vehicle** | **Familiarity with CMS systems.** |
| :--- | :--- |
|  SPARC | The average period of performance for a SPARC task order is 3.8 years. |
|  ADELE BPA | The average period of performance for an ADELE task order is 2.2 years. |
{: .table}

***Ability to define development and infrastructure requirements at the
BPA level so details are not missed in task orders***

Having certain requirements that can be found in all contracts that are
intended to go out under the vehicle can benefit from having these
requirements baked into the vehicle directly vs requiring justification
on each contract. This protects CMS from potentially missing common
contracting needs with each contract issued. This also cuts down on the
size of the proposal that needs to be reviewed with each task order.


|  **Vehicle** | **Requirements baked into the vehicle** |
| :--- | :--- |
|  SPARC | None. |
|  ADELE BPA | Agile methodologies. Digital Service requirements. |
{: .table}

Appendix F: Sample Statement of Objectives
------------------------------------------

## Modern Payment Services for the Medicare Fee for Service (FFS) Program Statement of Objectives (SOO)

## Overview and Background Information

As we create modernized systems at CMS, it also creates the need for
those systems to be able to communicate via real-time system-to-system
interfaces, powered by industry-standard open-source technology for
APIs. One of the most critical areas for systems across CMS to
interoperate with is with the Medicare claims ecosystem. For instance,
the Quality Payment Program (QPP) currently relies on a once-a-year flat
file transfer of payment adjustments to the Medicare Administrative
Contractors (MACs) to implement the actual payment rules that form the
purpose of the entire program. As other CMS systems modernize to provide
more information in real time, as well as rapidly implementing new
functionality to keep up with the constant innovations in Medicare, the
inflexibility of the shared systems that are responsible for claims
processing will continue to grow as a barrier to innovation if not
addressed. The shared systems, as the system that processes
approximately 1.2 billion claims a year, worth close to \$400 billion
dollars, must be able to change to meet the needs of the future, without
disruption to the critical services provided in the present.

A promising step in this direction is the Medicare fee-for-service
modernization effort led jointly by the Applications Management Group
(AMG), the Provider Billing Group (PBG), and the Medicare Contractor
Management Group (MCMG) at CMS. Together with an existing shared systems
maintainer, they have embarked on an effort to identify specific
projects within the shared systems that are effective incremental steps
towards modernization and have been building out proofs of concept to
determine the viability of each project. The United States Digital
Service (USDS) has recently joined this effort, bringing an additional
focus on identifying modules of the system that may be separated from
the mainframe deployment and deployed into a production-ready cloud
environment, enabling fully automated unit testing, integration,
deployment, and monitoring and alerting practices, as well as the use of
a wider array of open source tools and current industry standard
technologies.

The Medicare **Fee for Service** **(FFS) shared systems** are comprised
of four different systems: the Fiscal Intermediary Shared System (FISS)
which processes Medicare Part A claims and some Medicare Part B claims,
the Multi-Carrier System (MCS) which processes the bulk of Medicare Part
B claims, the ViPS Medicare System (VMS) for durable medical equipment
(DME), prosthetics, orthotics, and supplies claims, and the Common
Working File (CWF), which provides a “national view” of claims
processing, and performs additional eligibility verification,
utilization history, and pre-payment validation from that perspective.
Together, these four systems form the key core of systems which
determine if and how Medicare claims are paid out. These systems are
currently hosted on the CMS Virtual Data Centers (VDCs) and consist of
COBOL programs running on IBM z/OS mainframes in IBM’s Customer
Information Control System (CICS) environment. The primary users of
these systems are the Medicare Administrative Contractors (MACs), who
are responsible for receiving and processing claims from healthcare
providers in a timely and efficient manner. The MACs interface with the
shared systems through green-screen terminal interactions, and via
flat-file uploads and downloads from the shared systems. In addition,
each of the MACs has built their own ‘mid-tier’ systems, which are
proprietary systems designed to handle the workload and interface with
the shared systems.

The ongoing modernization effort is an attempt to take an incremental
approach to modernization – it focuses on finding portions or aspects of
the shared systems which may be good ‘proof of concepts’ for a
particular goal, and then setting a team to achieve that goal. The goals
of modernization are plentiful and varied, but they include updating the
languages and tools to current industry standards to allow the system to
be updated more easily and more frequently, refactors of the code to
resolve specific pain points, and modernizing the way that the shared
systems interact with other systems. This last point is critical, as CMS
is very interested to adopt an Application Program Interface (API)-first
approach to FFS modernization, making the functionality of the shared
systems accessible via a modern, REST API. This approach will drive
innovation in the way downstream systems make use of the systems and
their data, leading to better experiences for providers, beneficiaries,
and the entire Medicare community.

The ultimate goal of this incremental approach is to develop and create
processes and expertise that will accelerate and scale, enabling
long-term, large scale modernization in an agile manner. If the shared
systems are going to keep up with the pace of innovation in Medicare in
the long-term, allowing the system to adapt to needs five, ten, or
twenty years in the future that are impossible to predict now, we must
develop strategies for making substantial changes and improvements to
the system quickly. At this point in time, we don’t have the experience
to predict and plan changes at that scale, and so our focus is on
delivering and learning from smaller scale proof of concepts. We expect
these proof of concepts, though they start at a small scale, to form the
blueprints for repeatable processes for creating modularity, defining
system interdependencies, updating to modern languages and technologies,
and in general building a system that we can confidently change at
larger scales with confidence that we will not disrupt the critical
operations that the system supports in the present.

### How we expect this team to work

We expect a successful Modern Payment Services team to be flexible and
competent in solving both infrastructure and application development
problems, effectively applying common practices from successful private
companies to FFS Modernization efforts. This team will be responsible
both for driving progress as a partner on the effort to modernize
specific modules of the FFS shared systems, as well as building out the
modern infrastructure to host those modernized modules. This is an
exploratory effort, and we expect that the specific goals and objectives
of the team may shift over time as we learn more about the problem
space.

The FFS Modernization project is utilizing the Agile methodology, which
is a substantial shift from the waterfall-based operation of the core of
the FFS shared systems development. This new agile process and existing
waterfall process will need to co-exist and effectively interoperate if
this modernization is successful. We expect this team to have extensive
experience in effective agile environments, and a deep and thorough
understanding of the core principles of the Agile approach and why they
work. We will also expect this team to be comfortable explaining and
implementing agile without relying on pre-existing frameworks such as
Scrum or Kanban, as the team will be expected to first adapt to the
existing agile process used for modernization, and then play a role in
helping to evaluate and iterate on that process based on its merits in
this particular situation, rather than on its adherence to an existing
framework. In addition, we expect the team will be generally familiar
with tools supporting an agile process and will be able to adopt the
tools already in use (e.g., JIRA, Confluence, HipChat), as well as
suggest new tools as appropriate. These tools will be essential to
joining the collaboration with the existing members of the modernization
effort, which includes several groups at CMS from the Center for
Medicare (CM) and Office of Information Technology (OIT), as well as
modernization teams from the existing system maintainer, Perspecta.

## Problem Statement/Objectives

CMS seeks the skills of a **Modern Payment Services** team that is
well-versed in industry standard software architecture and development
practices using modern languages and tools, to join this ongoing
modernization effort on the FFS shared systems which will enable more
flexible development and real-time system-to-system integrations with
systems across CMS, such as quality payment systems, provider and
beneficiary support systems, etc.

We lay out two objectives below – one focused on building and
maintaining cloud infrastructure, and one focused on a collaborative
team joining existing proof of concept efforts undertaken by the
maintainer modernization team.

Objectives

## **Develop, monitor, and maintain a cloud infrastructure for modernized modules, using a DevOps informed approach to application deployment and maintenance**

USDS has begun developing a cloud infrastructure which is ultimately
intended to serve as the core environment in which modernized modules
will be deployed. We are looking for a team who can continue to iterate,
monitor, and maintain this system as the needs and scope of its
importance within the shared systems ecosystem evolves. We would expect
that this would be a scrum team of 3-4, focusing on DevOps/SRE
competencies, with some app development and project management
expertise.

Here are some specific areas of focus for the **Infrastructure** scrum
team:

**Enable effective, production-ready cloud operations**

* Found and nurture a DevOps culture following best practices laid out
in the SRE book[^1]
* Adopt and champion effective tooling to support a DevOps approach,
making effective use of tools already available (such as Splunk and
New Relic)
* Determine the risk tolerance of the modernized modules and devise
processes and infrastructure that ensure an appropriate level of
availability
* Implement practical and effective monitoring and alerting to enable
efficient detection and response to any discovered defects,
availability incidents, or security incidents
* Provide a team capable of fast and effective incident response which
mitigates issues within hours, and transparently communicates the
incident status to stakeholders
  * Incident response should have battle-tested mechanisms for rapidly
contacting and collaborating existing shared system developers and
maintainers

**Build tools to empower and accelerate development, testing, and
deployment in the cloud**

* Design and build infrastructure tooling to enable testing and
development that allows all stakeholders to have high confidence that
shared system updates function as expected, especially with respect to
their interaction and interface with other systems
  * Develop performance testing methodologies to ensure that updates
will not cause unacceptable negative impacts on nightly batch cycle
processing time.
* Build and maintain development, staging, and production environments
* Implement deployment tools that allow for fast, push-button
automated deployment and rollback of high availability applications
* Ensure tools are easy to use for development teams new to or
unfamiliar with modern cloud infrastructure, and with varying levels
of engineering expertise
* Improve and maintain a continuous integration system to build and
test updates
* Ensure the system is highly secure, and has a well understood threat
model which is actively monitored and updated
* Help navigate security compliance process to ensure efficient
delivery of updates on a regular schedule, for example gaining
approval of necessary Security Impact Analyses and supporting the
aspects of the shared systems’ Security Control Assessments impacted
by this work

## **Join and participate in selection, design, development, and deployment of proof of concepts and production modernization modules**

The existing modernization team, consisting of CMS (AMG, PBG, MCMG and
USDS) and the maintainer modernization team from Perspecta, is
continuing to identify and develop modules that will provide modern
interfaces to the FFS shared systems, allow for more flexible updates to
the shared systems, and resolve pain points for providers,
beneficiaries, MACs, and maintainers.

We are looking for an Application and Research team to join as members
of one or more of the three scrum teams which are currently working on
developing and delivering proof of concepts. We expect this team to
bring practical expertise in building modern APIs, architecting modern
distributed systems, cloud infrastructure, modern development tools, and
agile development processes to the proof of concept process. We also
expect for this team to bring a strong user research and service design
background, to help inform and advise CMS on the best path for
modernization moving forward. The existing members of the team, from the
system maintainer Perspecta, have considerable valuable expertise in the
FFS system itself, its architecture and functionality, the technologies
used to implement it and their strengths and limitations. They are very
familiar with the pain points facing the infrastructure and have a
number of ideas on how those could be addressed. They are also extremely
familiar with the business processes around FFS claims processing, which
is valuable information that should be used as the starting point for
the user research and service design elements of this team. We are
looking for a robust collaboration between these two groups, leveraging
the existing strengths of both groups and providing opportunities for
each group to learn from the other.

While we don’t expect expertise with Medicare claims processing or the
shared systems, as Perspecta will be primarily providing that, some
prior experience with Medicare claims data or processing would be
valuable for this team to have to enable a smoother integration and
collaboration with existing teams.

We expect that a team of around 4-7 would be appropriate for this work,
with that team either split between embedding on two existing sprint
teams or concentrating on a larger effort on a single sprint team. We
expect that this team would have primary competencies in modern
application development and API design, user experience research and
service design, as well as product and agile project management
expertise.

Here are some specific areas we would like this **Application and
Research** team to focus on;

**Effective use of modern technologies and methodologies**

* Embed developers on existing sprint teams, writing and review code
required to enable each module to be effectively used via a modern
interface, and if necessary, deployed into a modern cloud environment
* Effectively utilize modern technology within the modules where it
will add substantial value and is an appropriate solution, while also
recognizing areas where the benefits of migrating to a modern
technology are not substantial enough to warrant the move
* Assist in building modern development environment and testing tools
to facilitate maintenance and ongoing development of modules
* Ensure that the quality of the system remains high throughout the
shift to using modern Agile processes for development, testing, and
deployment
  * Provide mechanisms for thorough and efficient testing, ensuring the
rate of defects in the code is at a threshold determined by CMS to be
appropriate for the extremely critical sensitivity of this system
  * Ensure the system is highly secure, and has a well understood threat
model which is actively monitored and updated
  * Help navigate security compliance process for cloud environments to
ensure efficient delivery of updates on a regular schedule
  * Assess and optimize the performance impact of incorporating
modernized modules in the existing system

**Collaborative user research to inform, propose, design, and execute on
projects that achieve modernization goals**

* Perform user research to determine the impact (both positive and
negative) of each module on providers, beneficiaries, maintainers,
MACs (including systems cycle run times) and CMS stakeholders, and use
that understanding to provide suggestions to leverage technology to
maximize the benefit of modernization to the Medicare ecosystem
* Provide input and suggestions, stemming from research into the needs
of users and the design of the system, on the overall goals of the FFS
modernization program
* Participate in the design and architecture of the proofs of concept
and modernized modules in collaboration with the existing sprint
teams, providing expertise on effective usage of current industry
standard open source technologies
* Develop, execute, and iterate on effective methodologies that allow
the regular, efficient deployment of modernized modules to production

## Collaboration with existing groups

We expect this team’s work to be highly collaborative. The team will be
joining a preexisting modernization effort undertaken by several groups
within CMS, a USDS team, as well as a team already highly familiar with
the shared systems. The Modern Payment Services teams should identify
potential issues that could arise and interfere with their ability to
work effectively with the existing team and should have a plan to
address those issues. We have outlined important other teams and parties
below and specific expectations around each.

### CMS FFS Modernization Team (OIT/AMG, CM/PBG, CM/MCMG, USDS)

The existing CMS FFS Modernization team consists of stakeholders from
the Office of Information Technology’s Applications Management Group and
Center for Medicare’s Provider Billing Group and Medicare Contractor
Management Group, as well as members of the U.S. Digital Service at HHS
team. These CMS stakeholders serve both as the leadership and product
management team for the FFS modernization effort and are responsible for
making decisions about what work will be done and the direction of the
project.

We expect the Modern Payment Services team to serve a crucial role in
working together with the CMS FFS Modernization team on a day to day
basis, ensuring that their goals are met, and providing information and
expert advice on upcoming decisions or project direction.

### USDS Individual Contributors

In addition to USDS’ role as part of the CMS FFS Modernization team,
members of USDS are also serving in a number of roles as individual
contributors. This includes writing code, doing user research, and
generally participating in the FFS Modernization sprints as part of the
sprint teams. In general, we are currently providing expertise in areas
such as effective implementation of agile, practical design of modern
REST APIs, and practical use of cloud services, that we also expect that
the Modern Payment Services team to bring their expertise. This role
will shift for USDS as the project changes and matures.

We expect the Modern Payment Services team to start by engaging with the
USDS individual contributors to learn about what has already been built
and what the current state of the project is, and then to continue to
build off of the momentum and work that USDS has started.

### Shared System Maintainer Modernization Team

The Shared System Maintainer Modernization team is a team from Perspecta
(the vendor currently responsible for maintaining FISS and MCS) which is
focused on identifying and delivering selected proofs of concept for the
FFS Modernization team. They have devoted three sprint teams running
3-week sprints, each focusing on a specific proof of concept. The
Perspecta team bring expertise in understanding of the way that the FFS
systems work, both from a technical implementation perspective, as well
as a business perspective. They also have a strong familiarity with the
existing waterfall change management system that FFS uses to launch
production software.

We expect the Modern Payment Services Application and Research team to
join as team members onto one or more of the existing proof of concept
teams with Perspecta, to provide complementary expertise and perspective
on the modernization effort. Together, we expect that this team will
build proof of concepts that serve CMS’s modernization goals, and that
are turned into production-ready modules that are actually deployed,
providing real value to providers, beneficiaries, MACs, and other CMS
stakeholders. We also expect that this team will join with Perspecta to
carry out user research to provide CMS with information and insight into
planning future proofs of concept and modernization modules.

We expect the Modern Payment Services Infrastructure team to build and
maintain infrastructure which supports the deployment of proof of
concepts and production-ready modernization modules developed by
Perspecta which make use of cloud environments. The expectation is that
Perspecta developers will be able to easily deploy applications on
existing infrastructure, and that the Infrastructure team will be very
aware of the needs of the proof of concept sprint teams and work in
tandem with them to deliver what they need without becoming an
impediment to progress.

## Interaction with other stakeholders

### CMS Stakeholders

In addition to AMG, MCMG, and PBG, there are a number of other
stakeholders within CMS who will be affected by the FFS modernization
project. Our expectation for the Modern Payment Services teams is that
they will work to understand the goals and needs of all the CMS
stakeholders, and consider those in the design of the infrastructure, in
their contributions to the proofs of concept and production
modernization modules, and in their advice and input on the direction of
the modernization project.

### Shared System Maintainers and Operators

In addition to the Maintainer Modernization Team, there are other teams
involved in maintaining and operating the Shared Systems. Specifically,
there are teams who maintain the Virtual Data Centers (VDCs), as well as
the testing contractor, STC, responsible for coordinating and executing
testing. These teams are responsible for various activities, include
deploying the software, maintaining the code for each of the shared
systems, testing and monitoring the system, and operating the
datacenter.

We expect the Modern Payment Services Infrastructure team to forge a
strong working relationship with these operational teams, especially as
we push to launch the first production modernization modules. It is
essential that this team be involved in the defect and incident response
procedures that already exist for the FFS shared systems, so interfacing
with the new cloud infrastructure does not create process gaps in the
operation of the highly critical existing mainframe infrastructure. It
is also essential that the Modern Payment Services Infrastructure team
include the existing operators, maintainers, and application developers
in their own incident response processes for issues with the cloud
infrastructure, so that issues can be solved correctly and efficiently
as quickly as possible.

### Cloud Services Provider

As is common on other CMS projects such as QPP, AWS cloud services are
being procured through a vendor who is maintaining a network and
compliance framework on top of the existing AWS offerings. On QPP, this
was General Dynamics IT (GDIT).

We expect the Modern Payment Services Infrastructure team to forge a
strong working relationship with GDIT, so as to effectively work through
issues getting services provisioned or configured, understanding and
using the existing compliance infrastructure, and running incident
response operations.

### Medicare Administrative Contractors (MACs)

The Medicare Administrative Contractors, or MACs, are private health
care insurers that have been awarded a geographic jurisdiction to
process Medicare Part A and Part B medical claims, or DME claims for
Medicare FFS beneficiaries. CMS relies on a network of MACs to serve as
the primary operational contact between the Medicare FFS program and the
health care providers enrolled in the program. The MACs are the primary
users of the FFS Shared Systems, and also have a substantial amount of
involvement and input into how those shared systems work, as well as
lots of insight into how the business of Medicare FFS claims work.

One of the key benefits of modernizing the FFS Shared Systems is that it
will enable the MACs to improve the quality and efficiency of the
services that they provide to Medicare FFS providers and other claim
submitters, by enabling more real-time system-to-system interfaces
between the MACs’ internal systems and CMS’s shared systems.

We expect the Modern Payment Services Application and Research Team,
jointly with the existing Maintainer Modernization Team to research and
understand the current needs and pain points of the MACs, as well as
work directly with MAC implementation teams on proofs of concept their
following production modernization modules. The Maintainer Modernization
Team should have through their existing work on the shared systems, a
baseline of understanding about how the MACs work that can be leveraged
and built upon, while the MPS App and Research team is expected to bring
strong understanding and experience using modern user research and
[*service design*](https://en.wikipedia.org/wiki/Service_design)
techniques to accurately identify issues and design an effective
solution.

## Interaction with non-modernization development and deployment

As part of this modernization undertaking, we are looking to use Agile
techniques and methodology appropriately, developing a process which is
effective at driving improvement and responding to change while also
continues to effectively protect the critical availability, performance,
and security needs of the system.

The standard development and deployment process for the FFS systems is a
typical waterfall deployment process, with planning for changes that
will occur in January 2019 beginning six to nine months ahead of time
(July 2018 or even earlier). There are four quarterly releases,
occurring in January, April, July, and October. The majority of changes
that are made to the system are made in one of these four quarterly
releases. There does also exist an off-quarterly release process for
emergency fixes.

The existing process has been highly effective at meeting the critical
availability needs of the system, as well as maintaining the necessary
levels of performance and security. To accomplish this, however, has
involved a tradeoff which greatly limits the flexibility of the
deployment process by reducing the rate at which changes (and thus
instability) can be introduced into the system. The limitations of this
approach are an underlying cause for many of the pain points that are
motivating modernization.

One reason that the FFS Modernization team is piloting a move to a cloud
environment is to explore and establish mechanisms by which changes can
be made to production systems, meeting the same high availability,
performance, and security bar, while also allowing for the high degree
of flexibility and rapid response capabilities of a modern, agile
development approach. It is our expectation that the Modern Payment
Services teams will strive to achieve these objectives as well.

We expect the Modern Payment Services teams to contribute to and help
refine Agile development, testing, and deployment processes that ensure
availability, performance, and security at the same levels as the
existing systems. However, we also expect these teams to be cognizant of
the fact that we are making incremental changes to the way the FFS teams
work, and new processes must not disrupt the existing waterfall process
in ways that threaten the quality of the system. To this end, we expect
that the Modern Payment Services teams will become familiar with the
existing process as well, with help from the existing Maintainer
Modernization Team, so that they understand how to interact and
integrate with that system in an effective way.

[^1] https://landing.google.com/sre/book/index.html
